{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12761632,"sourceType":"datasetVersion","datasetId":8067341},{"sourceId":12761866,"sourceType":"datasetVersion","datasetId":8067500},{"sourceId":12771292,"sourceType":"datasetVersion","datasetId":8073723},{"sourceId":12781082,"sourceType":"datasetVersion","datasetId":8080387}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!apt-get update\n!apt-get install -y tesseract-ocr\n!pip install pytesseract","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport pytesseract\nimport numpy as np\nimport os\nfrom pathlib import Path\n\npytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'\n\ndef extract_text_from_frame(frame):\n    \"\"\"\n    Extract text from a single video frame using Tesseract OCR.\n    \"\"\"\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n    \n    gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n    \n    text = pytesseract.image_to_string(gray, lang='eng')\n    return text.strip()\n\ndef process_video(video_path, output_dir='output', frame_interval=30):\n    \"\"\"\n    Process a video file, extract text from frames, and save to a text file.\n    Args:\n        video_path (str): Path to the input video file.\n        output_dir (str): Directory to save extracted text.\n        frame_interval (int): Process every nth frame to reduce computation.\n    \"\"\"\n    os.makedirs(output_dir, exist_ok=True)\n    \n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        print(f\"Error: Could not open video file {video_path}\")\n        return\n    \n    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    print(f\"Video loaded: {frame_count} frames, {fps} FPS\")\n\n    extracted_texts = []\n    frame_number = 0\n    \n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n            \n        if frame_number % frame_interval == 0:\n            text = extract_text_from_frame(frame)\n            if text:  \n                extracted_texts.append(f\"Frame {frame_number}: {text}\")\n        \n        frame_number += 1\n    \n    \n    cap.release()\n    \n    output_file = os.path.join(output_dir, 'extracted_text.txt')\n    with open(output_file, 'w', encoding='utf-8') as f:\n        f.write('\\n'.join(extracted_texts))\n    \n    print(f\"Text extracted and saved to {output_file}\")\n    return extracted_texts\n\ndef main():\n    video_path = '/kaggle/input/ai-video/ai video.mp4'  # Replace with your video path\n    output_dir = '/kaggle/working/output'\n    \n    # Process the video and extract text\n    texts = process_video(video_path, output_dir)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-18T07:13:43.424Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}